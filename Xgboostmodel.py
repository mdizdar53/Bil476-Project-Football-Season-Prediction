import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import  accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.metrics import precision_score, recall_score, f1_score
# 1. Veriyi yÃ¼kle
df = pd.read_csv("bundesliga_with_efficiency.csv")

# 2. Hedef ve giriÅŸ deÄŸiÅŸkenlerini ayÄ±r
X = df.drop(columns=["Result"])
y = df["Result"]

# 3. Veriyi eÄŸitim ve test olarak bÃ¶l
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 4. XGBoost modelini tanÄ±mla ve eÄŸit
model = xgb.XGBClassifier(
    random_state=42,
    use_label_encoder=False,
    eval_metric='mlogloss'  # Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma iÃ§in uygun
)
model.fit(X_train, y_train)

# 5. Tahmin yap ve baÅŸarÄ±yÄ± Ã¶lÃ§
y_pred = model.predict(X_test)


# Accuracy
accuracy = accuracy_score(y_test, y_pred)

# Precision, Recall, F1-score (makro ortalama)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

# Tablo
metrics_df = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'],
    'Score': [accuracy, precision, recall, f1]
})

print(metrics_df)

# GÃ¶rselleÅŸtirme
sns.barplot(x='Metric', y='Score', data=metrics_df)
plt.ylim(0, 1)
plt.title("Model BaÅŸarÄ± Metrikleri - XGBoost")
plt.show()

# Ã–zellik Ã¶nemleri
importances = model.feature_importances_
importance_df = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

print("\nğŸ” XGBoost - Ã–znitelik Ã–nemi:")
print(importance_df)

# GÃ¶rselleÅŸtirme
plt.figure(figsize=(12, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))
plt.title("XGBoost - En Ã–nemli 15 Ã–zellik")
plt.tight_layout()
plt.show()

